{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation Systems:\n",
        "\n",
        "Objective - Estimate the rating a user might have to a target item.\n",
        "\n",
        "We describe the problem setting in terms of graph signal processing by creating a graph where items are nodes, rating similarities between items define edges, ratings given by users are graph signals on top of such a graph.\n",
        "\n",
        "We will use GNNs to learn the estimated rating that a user would give to an unrated item. The use of GNNs defined on such a graph will leverage the similarities between items to estimate the rating of target item based on the item the user has previously rated.\n"
      ],
      "metadata": {
        "id": "dIc2Km2v0_mV"
      },
      "id": "dIc2Km2v0_mV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset:\n",
        "\n",
        "MovieLens-100k => 100,000 ratings given by 943 users to 1,582 movies. (Ratings go from 1 to 5)\n",
        "\n",
        "*   Each movie is a node in the graph => 1,582 nodes => graphType = 'movie'\n",
        "\n",
        "Target movie is Star Wars(labelID = [50] => 583 users have rated the movie =>  Graph Signals\n",
        "\n",
        "*   The actual rating of the target movie $x_t$ is extracted as a label $y = x_t$ => Dataset {(x,y)}\n",
        "\n",
        "Use ratioTrain = 0.9 for training set and further split ratioValid = 0.1 for validation.\n",
        "\n",
        "Build graph from data => Edges are Pearson correlation => KNN = 10 nearest neighbors.\n"
      ],
      "metadata": {
        "id": "fJguMDhWM09L"
      },
      "id": "fJguMDhWM09L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Self-supervised vs. Supervised Learning:**\n",
        "\n",
        "Supervised Learning on Graphs: Labels come from external sources. Eg: Predict ratings of an interaction.\n",
        "\n",
        "Self-supervised learning on graphs: Signals come from graphs themselves. Eg: Link Prediction: predict if two nodes are connected.\n"
      ],
      "metadata": {
        "id": "e9xLIiq1sgKB"
      },
      "id": "e9xLIiq1sgKB"
    },
    {
      "cell_type": "markdown",
      "id": "51add8c9",
      "metadata": {
        "id": "51add8c9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from IPython.display import clear_output\n",
        "pt_version = torch.__version__\n",
        "print(pt_version)"
      ],
      "metadata": {
        "id": "bpCAHxkCWuIR",
        "outputId": "929b2edb-8a71-4135-f5cc-fc4787aee136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bpCAHxkCWuIR",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-sparse -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-cluster -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-${pt_version}.html\n",
        "!pip install torch-geometric\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "0IprMXOyWqdw"
      },
      "id": "0IprMXOyWqdw",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "59f2afec",
      "metadata": {
        "id": "59f2afec"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import model_selection, metrics, preprocessing\n",
        "import copy\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e5bbd8",
      "metadata": {
        "id": "a5e5bbd8"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c5b6bf8a",
      "metadata": {
        "id": "c5b6bf8a",
        "outputId": "fa1e5dc6-4123-48b5-f6ce-2d7ce32522c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ],
      "source": [
        "# download the dataset\n",
        "# https://grouplens.org/datasets/movielens/\n",
        "# \"Small: 100,000 ratings and 3,600 tag applications applied to 9,000 movies by 600 users. Last updated 9/2018\"\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'\n",
        "user_path = './ml-latest-small/users.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5248f04b",
      "metadata": {
        "id": "5248f04b",
        "outputId": "2623f8c9-e112-4d6a-c25c-1b5bdbf0d1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating  timestamp\n",
            "0       1        1     4.0  964982703\n",
            "1       1        3     4.0  964981247\n",
            "2       1        6     4.0  964982224\n",
            "3       1       47     5.0  964983815\n",
            "4       1       50     5.0  964982931\n",
            "9724\n",
            "610\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              userId        movieId         rating     timestamp\n",
              "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
              "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
              "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
              "min         1.000000       1.000000       0.500000  8.281246e+08\n",
              "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
              "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
              "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
              "max       610.000000  193609.000000       5.000000  1.537799e+09"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f5c9192-4524-482d-8795-8959dafcb747\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100836.000000</td>\n",
              "      <td>100836.000000</td>\n",
              "      <td>100836.000000</td>\n",
              "      <td>1.008360e+05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>326.127564</td>\n",
              "      <td>19435.295718</td>\n",
              "      <td>3.501557</td>\n",
              "      <td>1.205946e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>182.618491</td>\n",
              "      <td>35530.987199</td>\n",
              "      <td>1.042529</td>\n",
              "      <td>2.162610e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>8.281246e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>177.000000</td>\n",
              "      <td>1199.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.019124e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>325.000000</td>\n",
              "      <td>2991.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>1.186087e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>477.000000</td>\n",
              "      <td>8122.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.435994e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>610.000000</td>\n",
              "      <td>193609.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.537799e+09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f5c9192-4524-482d-8795-8959dafcb747')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f5c9192-4524-482d-8795-8959dafcb747 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f5c9192-4524-482d-8795-8959dafcb747');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "rating_df = pd.read_csv(rating_path)\n",
        "\n",
        "print(rating_df.head())\n",
        "\n",
        "print(len(rating_df['movieId'].unique()))\n",
        "print(len(rating_df['userId'].unique()))\n",
        "\n",
        "rating_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d3c20490",
      "metadata": {
        "id": "d3c20490"
      },
      "outputs": [],
      "source": [
        "# perform encoding preprocessing to ensure that user_id and item_id are both \n",
        "# in the range of [0, unique_count] so it won't cause out of bound issue when indexing embeddings\n",
        "lbl_user = preprocessing.LabelEncoder()\n",
        "lbl_movie = preprocessing.LabelEncoder()\n",
        "\n",
        "rating_df.userId = lbl_user.fit_transform(rating_df.userId.values)\n",
        "rating_df.movieId = lbl_movie.fit_transform(rating_df.movieId.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5527b80b",
      "metadata": {
        "id": "5527b80b",
        "outputId": "69e3085c-3aa1-4c61-88da-5dc50d7a5a50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "609\n",
            "9723\n"
          ]
        }
      ],
      "source": [
        "print(rating_df.userId.max())\n",
        "print(rating_df.movieId.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "ea7018cc",
      "metadata": {
        "id": "ea7018cc",
        "outputId": "6ef15267-7589-4d74-dbbe-49eb84620ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.0    26818\n",
              "3.0    20047\n",
              "5.0    13211\n",
              "3.5    13136\n",
              "4.5     8551\n",
              "2.0     7551\n",
              "2.5     5550\n",
              "1.0     2811\n",
              "1.5     1791\n",
              "0.5     1370\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "rating_df.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a1e6b7e5",
      "metadata": {
        "id": "a1e6b7e5"
      },
      "outputs": [],
      "source": [
        "# load edges between users and movies\n",
        "def load_edge_csv(df, \n",
        "                  src_index_col, \n",
        "                  dst_index_col, \n",
        "                  link_index_col, \n",
        "                  rating_threshold=3):\n",
        "    \"\"\"Loads csv containing edges between users and items\n",
        "\n",
        "    Args:\n",
        "        src_index_col (str): column name of users\n",
        "        dst_index_col (str): column name of items\n",
        "        link_index_col (str): column name of user item interaction\n",
        "        rating_threshold (int, optional): Threshold to determine positivity of edge. Defaults to 4.\n",
        "\n",
        "    Returns:\n",
        "        list of list: edge_index -- 2 by N matrix containing the node ids of N user-item edges\n",
        "        N here is the number of interactions\n",
        "    \"\"\"\n",
        "    \n",
        "    edge_index = None\n",
        "    \n",
        "    # Constructing COO format edge_index from input rating events\n",
        "    \n",
        "    # get user_ids from rating events in the order of occurance\n",
        "    src = [user_id for user_id in  df['userId']]    \n",
        "    # get movie_id from rating events in the order of occurance\n",
        "    dst = [(movie_id) for movie_id in df['movieId']]\n",
        "\n",
        "    # apply rating threshold\n",
        "    edge_attr = torch.from_numpy(df[link_index_col].values).view(-1, 1).to(torch.long) >= rating_threshold\n",
        "\n",
        "    edge_index = [[], []]\n",
        "    for i in range(edge_attr.shape[0]):\n",
        "        if edge_attr[i]:\n",
        "            edge_index[0].append(src[i])\n",
        "            edge_index[1].append(dst[i])\n",
        "    return edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "49a1fc26",
      "metadata": {
        "id": "49a1fc26",
        "outputId": "11569c2d-f417-4713-8f41-ec22d6d8fae1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 x 48580\n"
          ]
        }
      ],
      "source": [
        "edge_index = load_edge_csv(\n",
        "    rating_df,\n",
        "    src_index_col='userId',\n",
        "    dst_index_col='movieId',\n",
        "    link_index_col='rating',\n",
        "    rating_threshold=3.5, \n",
        ")\n",
        "\n",
        "print(f\"{len(edge_index)} x {len(edge_index[0])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fc37da10",
      "metadata": {
        "id": "fc37da10",
        "outputId": "07dd0c78-c3cc-4918-9776-43aababc0ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
            "        [   0,    2,    5,  ..., 9443, 9444, 9445]])\n",
            "torch.Size([2, 48580])\n"
          ]
        }
      ],
      "source": [
        "# Convert to tensor\n",
        "# We use LongTensor here because the .propagate() method in the model needs either LongTensor or SparseTensor\n",
        "edge_index = torch.LongTensor(edge_index) \n",
        "print(edge_index)\n",
        "print(edge_index.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8c38603a",
      "metadata": {
        "id": "8c38603a"
      },
      "outputs": [],
      "source": [
        "# Note: this is the total num_users and num_movies before we apply the rating_threshold\n",
        "num_users = len(rating_df['userId'].unique())\n",
        "num_movies = len(rating_df['movieId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b4e70928",
      "metadata": {
        "id": "b4e70928"
      },
      "outputs": [],
      "source": [
        "num_interactions = edge_index.shape[1]\n",
        "\n",
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(all_indices, \n",
        "                                               test_size=0.2, \n",
        "                                               random_state=1)\n",
        "\n",
        "val_indices, test_indices = train_test_split(test_indices, \n",
        "                                             test_size=0.5, \n",
        "                                             random_state=1)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ffc7e5e8",
      "metadata": {
        "id": "ffc7e5e8",
        "outputId": "6a508e8b-63e2-46a0-9486-c537dc27551e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_users 610, num_movies 9724, num_interactions 48580\n",
            "train_edge_index tensor([[ 605,  110,  442,  ...,   65,  161,  427],\n",
            "        [1110, 9619, 1283,  ..., 4640,  443,  827]])\n",
            "10334\n",
            "torch.Size([609])\n",
            "torch.Size([5676])\n"
          ]
        }
      ],
      "source": [
        "print(f\"num_users {num_users}, num_movies {num_movies}, num_interactions {num_interactions}\")\n",
        "print(f\"train_edge_index {train_edge_index}\")\n",
        "print((num_users + num_movies))\n",
        "print(torch.unique(train_edge_index[0]).size())\n",
        "print(torch.unique(train_edge_index[1]).size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "e5daf702",
      "metadata": {
        "id": "e5daf702"
      },
      "outputs": [],
      "source": [
        "def convert_r_mat_edge_index_to_adj_mat_edge_index(input_edge_index):\n",
        "    R = torch.zeros((num_users, num_movies))\n",
        "    for i in range(len(input_edge_index[0])):\n",
        "        row_idx = input_edge_index[0][i]\n",
        "        col_idx = input_edge_index[1][i]\n",
        "        R[row_idx][col_idx] = 1\n",
        "\n",
        "    R_transpose = torch.transpose(R, 0, 1)\n",
        "    adj_mat = torch.zeros((num_users + num_movies , num_users + num_movies))\n",
        "    adj_mat[: num_users, num_users :] = R.clone()\n",
        "    adj_mat[num_users :, : num_users] = R_transpose.clone()\n",
        "    adj_mat_coo = adj_mat.to_sparse_coo()\n",
        "    adj_mat_coo = adj_mat_coo.indices()\n",
        "    return adj_mat_coo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "005195ba",
      "metadata": {
        "id": "005195ba"
      },
      "outputs": [],
      "source": [
        "def convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index):\n",
        "    sparse_input_edge_index = SparseTensor(row=input_edge_index[0], \n",
        "                                           col=input_edge_index[1], \n",
        "                                           sparse_sizes=((num_users + num_movies), num_users + num_movies))\n",
        "    adj_mat = sparse_input_edge_index.to_dense()\n",
        "    interact_mat = adj_mat[: num_users, num_users :]\n",
        "    r_mat_edge_index = interact_mat.to_sparse_coo().indices()\n",
        "    return r_mat_edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f6e41ca6",
      "metadata": {
        "id": "f6e41ca6"
      },
      "outputs": [],
      "source": [
        "# convert from r_mat (interaction matrix) edge index to adjescency matrix's edge index \n",
        "# so we can feed it to model\n",
        "train_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(train_edge_index)\n",
        "val_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(val_edge_index)\n",
        "test_edge_index = convert_r_mat_edge_index_to_adj_mat_edge_index(test_edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9ced999a",
      "metadata": {
        "id": "9ced999a",
        "outputId": "d8eea1a6-c092-4145-ed87-43557a7d08c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     0,     0,  ..., 10326, 10327, 10333],\n",
            "        [  610,   612,   653,  ...,   183,   183,   330]])\n",
            "torch.Size([2, 77728])\n",
            "tensor([[    0,     0,     0,  ..., 10226, 10236, 10240],\n",
            "        [  615,   794,  2010,  ...,   317,   204,   413]])\n",
            "torch.Size([2, 9716])\n",
            "tensor([[    0,     0,     0,  ..., 10301, 10302, 10329],\n",
            "        [  811,  1086,  1095,  ...,   585,   585,   183]])\n",
            "torch.Size([2, 9716])\n"
          ]
        }
      ],
      "source": [
        "print(train_edge_index)\n",
        "print(train_edge_index.size())\n",
        "print(val_edge_index)\n",
        "print(val_edge_index.size())\n",
        "print(test_edge_index)\n",
        "print(test_edge_index.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d8a112c1",
      "metadata": {
        "id": "d8a112c1"
      },
      "outputs": [],
      "source": [
        "# helper function for training and compute BPR loss\n",
        "# since this is a self-supervised learning, we are relying on the graph structure itself and \n",
        "# we don't have label other than the graph structure so we need to the folloing function\n",
        "# which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    # structured_negative_sampling is a pyG library\n",
        "    # Samples a negative edge :obj:`(i,k)` for every positive edge\n",
        "    # :obj:`(i,j)` in the graph given by :attr:`edge_index`, and returns it as a\n",
        "    # tuple of the form :obj:`(i,j,k)`.\n",
        "    #\n",
        "    #         >>> edge_index = torch.as_tensor([[0, 0, 1, 2],\n",
        "    #         ...                               [0, 1, 2, 3]])\n",
        "    #         >>> structured_negative_sampling(edge_index)\n",
        "    #         (tensor([0, 0, 1, 2]), tensor([0, 1, 2, 3]), tensor([2, 3, 0, 2]))\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    \n",
        "    # 3 x edge_index_len\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    \n",
        "    # here is whhen we actually perform the batch sampe\n",
        "    # Return a k sized list of population elements chosen with replacement.\n",
        "    indices = random.choices([i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    \n",
        "    batch = edges[:, indices]\n",
        "    \n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3688310d",
      "metadata": {
        "id": "3688310d"
      },
      "source": [
        "# Implementing LightGCN\n",
        "\n",
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9e8cbb67",
      "metadata": {
        "id": "9e8cbb67"
      },
      "outputs": [],
      "source": [
        "# defines LightGCN model \n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, \n",
        "                 num_items, \n",
        "                 embedding_dim=64, # define the embding vector length for each node\n",
        "                 K=3, \n",
        "                 add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.K = K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        # define user and item embedding for direct look up. \n",
        "        # embedding dimension: num_user/num_item x embedding_dim\n",
        "        \n",
        "        self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        \n",
        "        self.items_emb = nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        # \"Fills the input Tensor with values drawn from the normal distribution\"\n",
        "        # according to LightGCN paper, this gives better performance\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: Tensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "            compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "            \\tilde_A = D^(-1/2) * A * D^(-1/2)    according to LightGCN paper\n",
        "        \n",
        "            this is essentially a metrix operation way to get 1/ (sqrt(n_neighbors_i) * sqrt(n_neighbors_j))\n",
        "\n",
        "        \n",
        "            if your original edge_index look like\n",
        "            tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                    [   0,    2,    5,  ..., 9444, 9445, 9485]])\n",
        "                    \n",
        "                    torch.Size([2, 99466])\n",
        "                    \n",
        "            then this will output: \n",
        "                (\n",
        "                 tensor([[   0,    0,    0,  ...,  609,  609,  609],\n",
        "                         [   0,    2,    5,  ..., 9444, 9445, 9485]]), \n",
        "                 tensor([0.0047, 0.0096, 0.0068,  ..., 0.0592, 0.0459, 0.1325])\n",
        "                 )\n",
        "                 \n",
        "              where edge_index_norm[0] is just the original edge_index\n",
        "              \n",
        "              and edge_index_norm[1] is the symmetrically normalization term. \n",
        "              \n",
        "            under the hood it's basically doing\n",
        "                def compute_gcn_norm(edge_index, emb):\n",
        "                    emb = emb.weight\n",
        "                    from_, to_ = edge_index\n",
        "                    deg = degree(to_, emb.size(0), dtype=emb.dtype)\n",
        "                    deg_inv_sqrt = deg.pow(-0.5)\n",
        "                    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "                    norm = deg_inv_sqrt[from_] * deg_inv_sqrt[to_]\n",
        "\n",
        "                    return norm\n",
        "                 \n",
        "                \n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index=edge_index, \n",
        "                                   add_self_loops=self.add_self_loops)\n",
        "\n",
        "        # concat the user_emb and item_emb as the layer0 embing matrix\n",
        "        # size will be (n_users + n_items) x emb_vector_len.   e.g: 10334 x 64\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "\n",
        "        embs = [emb_0] # save the layer0 emb to the embs list\n",
        "        \n",
        "        # emb_k is the emb that we are actually going to push it through the graph layers\n",
        "        # as described in lightGCN paper formula 7\n",
        "        emb_k = emb_0 \n",
        "\n",
        "        # push the embedding of all users and items through the Graph Model K times.\n",
        "        # K here is the number of layers\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index=edge_index_norm[0], x=emb_k, norm=edge_index_norm[1])\n",
        "            embs.append(emb_k)\n",
        "            \n",
        "            \n",
        "        # this is doing the formula8 in LightGCN paper  \n",
        "            \n",
        "        # the stacked embs is a list of embedding matrix at each layer\n",
        "        #    it's of shape n_nodes x (n_layers + 1) x emb_vector_len. \n",
        "        #        e.g: torch.Size([10334, 4, 64])\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        \n",
        "        # From LightGCn paper: \"In our experiments, we find that setting Î±_k uniformly as 1/(K + 1)\n",
        "        #    leads to good performance in general.\"\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "\n",
        "        # splits into e_u^K and e_i^K\n",
        "        users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) \n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        # here using .weight to get the tensor weights from n.Embedding\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j is of shape:  edge_index_len x emb_vector_len\n",
        "        #    e.g: torch.Size([77728, 64]\n",
        "        #\n",
        "        # x_j is basically the embedding of all the neighbors based on the src_list in coo edge index\n",
        "        # \n",
        "        # elementwise multiply by the symmetrically norm. So it's essentiall what formula 7 in LightGCN\n",
        "        # paper does but here we are using edge_index rather than Adj Matrix\n",
        "        return norm.view(-1, 1) * x_j\n",
        "\n",
        "layers = 3    \n",
        "model = LightGCN(num_users=num_users, \n",
        "                 num_items=num_movies, \n",
        "                 K=layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ea1884a0",
      "metadata": {
        "id": "ea1884a0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ffad4fa8",
      "metadata": {
        "id": "ffad4fa8"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "cee24091",
      "metadata": {
        "id": "cee24091"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(users_emb_final, \n",
        "             users_emb_0, \n",
        "             pos_items_emb_final, \n",
        "             pos_items_emb_0, \n",
        "             neg_items_emb_final, \n",
        "             neg_items_emb_0, \n",
        "             lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "\n",
        "    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
        "    \n",
        "    loss = bpr_loss + reg_loss\n",
        "    \n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c5c914",
      "metadata": {
        "id": "e7c5c914"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "Recall@k and Precision@k is just applying only the topK recommended items and then for the overall\n",
        "Recall@k and Precision@k, it's just averaged by the number of users\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4a6dc66e",
      "metadata": {
        "id": "4a6dc66e"
      },
      "outputs": [],
      "source": [
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"\n",
        "    Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges \n",
        "\n",
        "    Returns:\n",
        "        dict: user -> list of positive items for each \n",
        "    \"\"\"\n",
        "    \n",
        "    # key: user_id, val: item_id list\n",
        "    user_pos_items = {}\n",
        "    \n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        \n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        \n",
        "        user_pos_items[user].append(item)\n",
        "        \n",
        "    return user_pos_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "ace2aa34",
      "metadata": {
        "id": "ace2aa34"
      },
      "outputs": [],
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list[list[long]]): list of lists of item_ids. Cntaining highly rated items of each user. \n",
        "                            In other words, this is the list of true_relevant_items for each user\n",
        "                            \n",
        "        r (list[list[boolean]]): list of lists indicating whether each top k item recommended to each user\n",
        "                            is a top k ground truth (true relevant) item or not\n",
        "                            \n",
        "        k (int): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    \n",
        "    # number of correctly predicted items per user\n",
        "    # -1 here means I want to sum at the inner most dimension\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  \n",
        "    \n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i]) for i in range(len(groundTruth))])\n",
        "    \n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "fa475ca5",
      "metadata": {
        "id": "fa475ca5"
      },
      "outputs": [],
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fe2d3e12",
      "metadata": {
        "id": "fe2d3e12"
      },
      "outputs": [],
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, \n",
        "                input_edge_index, # adj_mat based edge index\n",
        "                input_exclude_edge_indices, # adj_mat based exclude edge index\n",
        "                k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        \n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        \n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        \n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get the embedding tensor at layer 0 after training\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "    \n",
        "\n",
        "    # convert adj_mat based edge index to r_mat based edge index so we have have \n",
        "    # the first list being user_ids and second list being item_ids for the edge index \n",
        "    edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
        "\n",
        "    # This is to exclude the edges we have seen before in our predicted interaction matrix (r_mat_rating)\n",
        "    # E.g: for validation set, we want want to exclude all the edges in training set\n",
        "    exclude_edge_indices = [convert_adj_mat_edge_index_to_r_mat_edge_index(exclude_edge_index) \\\n",
        "                                      for exclude_edge_index in input_exclude_edge_indices]\n",
        "\n",
        "     \n",
        "\n",
        "    # Generate predicted interaction matrix (r_mat_rating)    \n",
        "    # (num_users x 64) dot_product (num_item x 64).T \n",
        "    r_mat_rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "    \n",
        "    # shape: num_users x num_item\n",
        "    rating = r_mat_rating\n",
        "   \n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        # it's a dict: user -> positive item list\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        \n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            # [user] * len(item) can give us [user1, user1, user1...] with len of len(item)\n",
        "            # this makes easier to do the masking below\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "   \n",
        "        # set the excluded entry in the rat_mat_rating matrix to a very small number\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10) \n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    # dict of user -> pos_item list\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list of lists\n",
        "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "\n",
        "    # r here is \"pred_relevant_items â© actually_relevant_items\" list for each user\n",
        "    r = []\n",
        "    for user in users:\n",
        "        user_true_relevant_item = test_user_pos_items[user.item()]\n",
        "        # list of Booleans to store whether or not a given item in the top_K_items for a given user \n",
        "        # is also present in user_true_relevant_item.\n",
        "        # this is later on used to compute n_rel_and_rec_k\n",
        "        label = list(map(lambda x: x in user_true_relevant_item, top_K_items[user]))\n",
        "        r.append(label)\n",
        "        \n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b69b4158",
      "metadata": {
        "id": "b69b4158"
      },
      "outputs": [],
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, \n",
        "               edge_index, # adj_mat based edge index\n",
        "               exclude_edge_indices,  # adj_mat based exclude edge index\n",
        "               k, \n",
        "               lambda_val\n",
        "              ):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(edge_index)\n",
        "    \n",
        "    r_mat_edge_index = convert_adj_mat_edge_index_to_r_mat_edge_index(edge_index)\n",
        "    \n",
        "    edges = structured_negative_sampling(r_mat_edge_index, contains_neg_self_loops=False)\n",
        "    \n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    \n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    \n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    \n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, \n",
        "                    users_emb_0, \n",
        "                    pos_items_emb_final, \n",
        "                    pos_items_emb_0,\n",
        "                    neg_items_emb_final, \n",
        "                    neg_items_emb_0, \n",
        "                    lambda_val).item()\n",
        "\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(model, \n",
        "                                          edge_index, \n",
        "                                          exclude_edge_indices, \n",
        "                                          k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "af8b0cc8",
      "metadata": {
        "id": "af8b0cc8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "316ba67b",
      "metadata": {
        "id": "316ba67b"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c4cee1b8",
      "metadata": {
        "id": "c4cee1b8"
      },
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "EPOCHS = 10\n",
        "# ITERATIONS = 500\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20\n",
        "LAMBDA = 1e-6\n",
        "# LAMBDA = 1/2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1d3b2d75",
      "metadata": {
        "id": "1d3b2d75",
        "outputId": "68bc1c21-4d21-43dc-d512-34e0a9f5530f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cpu.\n"
          ]
        }
      ],
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "val_edge_index = val_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "371bdb47",
      "metadata": {
        "id": "371bdb47"
      },
      "outputs": [],
      "source": [
        "def get_embs_for_bpr(model, input_edge_index):\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(input_edge_index)\n",
        "    \n",
        "\n",
        "    edge_index_to_use = convert_adj_mat_edge_index_to_r_mat_edge_index(input_edge_index)\n",
        "    \n",
        "    # mini batching for eval and calculate loss \n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(BATCH_SIZE, edge_index_to_use)\n",
        "    \n",
        "    # This is to push tensor to device so if we are using GPU\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    \n",
        " \n",
        "    # we need layer0 embeddings and the final embeddings (computed from 0...K layer) for BPR loss computing\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[neg_item_indices], items_emb_0[neg_item_indices]\n",
        "   \n",
        "    return users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "fcbf4944",
      "metadata": {
        "id": "fcbf4944"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "5b7f792e",
      "metadata": {
        "id": "5b7f792e",
        "outputId": "ad9c95cf-75fd-437f-a072-d2c71cf98e25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917,
          "referenced_widgets": [
            "c63342d6c5cb4032ae29f4c95b3b3ae1",
            "279f2ea35143469fb5b7095846f3127d",
            "5c733606b4c84969a92a1887b4aff063",
            "11073034aa7e4cc5b946f6fea772e9c0",
            "8da8ab5809b34c9a98bc19e1227ddb1d",
            "0f80221129484bd9a572500f0efe34a2",
            "42f47230c84e4301a9ebef4db8939560",
            "e96eebab901b4360bc64f1232f533be7",
            "1cb666ea2e2b483590c27ff9714e1de5",
            "5417742a2e6746149121185dce42df29",
            "35f791d750da43adb152af980f7a121a"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c63342d6c5cb4032ae29f4c95b3b3ae1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/10000] train_loss: -0.69282, val_loss: -0.6995, val_recall@20: 0.00274, val_precision@20: 0.00099, val_ndcg@20: 0.00231\n",
            "[Iteration 200/10000] train_loss: -6.95393, val_loss: -5.24753, val_recall@20: 0.05183, val_precision@20: 0.01763, val_ndcg@20: 0.03239\n",
            "[Iteration 400/10000] train_loss: -29.5191, val_loss: -21.24659, val_recall@20: 0.09002, val_precision@20: 0.02749, val_ndcg@20: 0.04999\n",
            "[Iteration 600/10000] train_loss: -62.57068, val_loss: -45.17301, val_recall@20: 0.10023, val_precision@20: 0.03183, val_ndcg@20: 0.0613\n",
            "[Iteration 800/10000] train_loss: -101.56174, val_loss: -74.08066, val_recall@20: 0.10017, val_precision@20: 0.03345, val_ndcg@20: 0.06418\n",
            "[Iteration 1000/10000] train_loss: -152.72639, val_loss: -108.31877, val_recall@20: 0.11681, val_precision@20: 0.03671, val_ndcg@20: 0.07233\n",
            "[Iteration 1200/10000] train_loss: -198.48291, val_loss: -144.11984, val_recall@20: 0.12443, val_precision@20: 0.03797, val_ndcg@20: 0.08263\n",
            "[Iteration 1400/10000] train_loss: -266.05234, val_loss: -184.64018, val_recall@20: 0.12194, val_precision@20: 0.03797, val_ndcg@20: 0.08247\n",
            "[Iteration 1600/10000] train_loss: -310.24176, val_loss: -225.43163, val_recall@20: 0.12425, val_precision@20: 0.03861, val_ndcg@20: 0.08819\n",
            "[Iteration 1800/10000] train_loss: -356.18832, val_loss: -264.13776, val_recall@20: 0.13077, val_precision@20: 0.03978, val_ndcg@20: 0.08895\n",
            "[Iteration 2000/10000] train_loss: -419.86026, val_loss: -304.61002, val_recall@20: 0.13116, val_precision@20: 0.03996, val_ndcg@20: 0.09216\n",
            "[Iteration 2200/10000] train_loss: -472.52786, val_loss: -344.72504, val_recall@20: 0.13434, val_precision@20: 0.04078, val_ndcg@20: 0.09358\n",
            "[Iteration 2400/10000] train_loss: -530.25549, val_loss: -388.17181, val_recall@20: 0.13504, val_precision@20: 0.04132, val_ndcg@20: 0.09332\n",
            "[Iteration 2600/10000] train_loss: -608.90613, val_loss: -431.17264, val_recall@20: 0.13695, val_precision@20: 0.04105, val_ndcg@20: 0.09119\n",
            "[Iteration 2800/10000] train_loss: -636.64758, val_loss: -468.57779, val_recall@20: 0.13843, val_precision@20: 0.04069, val_ndcg@20: 0.09431\n",
            "[Iteration 3000/10000] train_loss: -689.41333, val_loss: -497.28561, val_recall@20: 0.13581, val_precision@20: 0.04114, val_ndcg@20: 0.09261\n",
            "[Iteration 3200/10000] train_loss: -698.76837, val_loss: -544.92792, val_recall@20: 0.13574, val_precision@20: 0.04132, val_ndcg@20: 0.09507\n",
            "[Iteration 3400/10000] train_loss: -762.59192, val_loss: -573.85022, val_recall@20: 0.1355, val_precision@20: 0.04132, val_ndcg@20: 0.09409\n",
            "[Iteration 3600/10000] train_loss: -879.50671, val_loss: -615.54297, val_recall@20: 0.13678, val_precision@20: 0.04132, val_ndcg@20: 0.09364\n",
            "[Iteration 3800/10000] train_loss: -869.05096, val_loss: -641.17224, val_recall@20: 0.13821, val_precision@20: 0.04186, val_ndcg@20: 0.0952\n",
            "[Iteration 4000/10000] train_loss: -934.78027, val_loss: -677.69318, val_recall@20: 0.13988, val_precision@20: 0.04231, val_ndcg@20: 0.09517\n",
            "[Iteration 4200/10000] train_loss: -963.98035, val_loss: -706.06458, val_recall@20: 0.13924, val_precision@20: 0.04186, val_ndcg@20: 0.09392\n",
            "[Iteration 4400/10000] train_loss: -1086.70862, val_loss: -741.4043, val_recall@20: 0.1392, val_precision@20: 0.0415, val_ndcg@20: 0.09582\n",
            "[Iteration 4600/10000] train_loss: -1094.45459, val_loss: -764.81519, val_recall@20: 0.14068, val_precision@20: 0.04186, val_ndcg@20: 0.09394\n",
            "[Iteration 4800/10000] train_loss: -1100.4054, val_loss: -796.78668, val_recall@20: 0.14183, val_precision@20: 0.04213, val_ndcg@20: 0.09403\n",
            "[Iteration 5000/10000] train_loss: -1159.42651, val_loss: -821.8584, val_recall@20: 0.141, val_precision@20: 0.04204, val_ndcg@20: 0.09435\n",
            "[Iteration 5200/10000] train_loss: -1228.44568, val_loss: -851.14233, val_recall@20: 0.14196, val_precision@20: 0.04213, val_ndcg@20: 0.09443\n",
            "[Iteration 5400/10000] train_loss: -1178.59412, val_loss: -877.67316, val_recall@20: 0.14082, val_precision@20: 0.04177, val_ndcg@20: 0.09442\n",
            "[Iteration 5600/10000] train_loss: -1215.64587, val_loss: -898.33527, val_recall@20: 0.14143, val_precision@20: 0.04241, val_ndcg@20: 0.09737\n",
            "[Iteration 5800/10000] train_loss: -1305.13245, val_loss: -910.7937, val_recall@20: 0.14262, val_precision@20: 0.04231, val_ndcg@20: 0.09802\n",
            "[Iteration 6000/10000] train_loss: -1269.35388, val_loss: -944.36511, val_recall@20: 0.14247, val_precision@20: 0.0425, val_ndcg@20: 0.09804\n",
            "[Iteration 6200/10000] train_loss: -1347.40295, val_loss: -956.32037, val_recall@20: 0.14578, val_precision@20: 0.04286, val_ndcg@20: 0.09729\n",
            "[Iteration 6400/10000] train_loss: -1352.64514, val_loss: -981.32092, val_recall@20: 0.1456, val_precision@20: 0.04277, val_ndcg@20: 0.09742\n",
            "[Iteration 6600/10000] train_loss: -1395.34729, val_loss: -1002.07983, val_recall@20: 0.14605, val_precision@20: 0.04295, val_ndcg@20: 0.09656\n",
            "[Iteration 6800/10000] train_loss: -1401.89197, val_loss: -1022.46265, val_recall@20: 0.14473, val_precision@20: 0.04268, val_ndcg@20: 0.0985\n",
            "[Iteration 7000/10000] train_loss: -1448.67139, val_loss: -1038.9314, val_recall@20: 0.14397, val_precision@20: 0.04259, val_ndcg@20: 0.09776\n",
            "[Iteration 7200/10000] train_loss: -1424.43896, val_loss: -1051.51404, val_recall@20: 0.14349, val_precision@20: 0.0425, val_ndcg@20: 0.09832\n",
            "[Iteration 7400/10000] train_loss: -1537.75281, val_loss: -1069.05676, val_recall@20: 0.14356, val_precision@20: 0.0425, val_ndcg@20: 0.09569\n",
            "[Iteration 7600/10000] train_loss: -1512.98425, val_loss: -1090.80249, val_recall@20: 0.14523, val_precision@20: 0.04277, val_ndcg@20: 0.09626\n",
            "[Iteration 7800/10000] train_loss: -1528.35217, val_loss: -1098.46741, val_recall@20: 0.14402, val_precision@20: 0.04241, val_ndcg@20: 0.09596\n",
            "[Iteration 8000/10000] train_loss: -1475.30847, val_loss: -1088.41797, val_recall@20: 0.14368, val_precision@20: 0.04222, val_ndcg@20: 0.09607\n",
            "[Iteration 8200/10000] train_loss: -1540.83801, val_loss: -1123.60364, val_recall@20: 0.14339, val_precision@20: 0.04222, val_ndcg@20: 0.09595\n",
            "[Iteration 8400/10000] train_loss: -1627.40662, val_loss: -1130.72937, val_recall@20: 0.1442, val_precision@20: 0.04241, val_ndcg@20: 0.09598\n",
            "[Iteration 8600/10000] train_loss: -1482.5918, val_loss: -1142.8031, val_recall@20: 0.14343, val_precision@20: 0.04241, val_ndcg@20: 0.09575\n",
            "[Iteration 8800/10000] train_loss: -1578.50562, val_loss: -1156.73303, val_recall@20: 0.14361, val_precision@20: 0.04259, val_ndcg@20: 0.0955\n",
            "[Iteration 9000/10000] train_loss: -1644.16565, val_loss: -1172.88391, val_recall@20: 0.14361, val_precision@20: 0.04259, val_ndcg@20: 0.09588\n",
            "[Iteration 9200/10000] train_loss: -1635.71497, val_loss: -1176.7677, val_recall@20: 0.14316, val_precision@20: 0.04241, val_ndcg@20: 0.09548\n",
            "[Iteration 9400/10000] train_loss: -1633.07068, val_loss: -1193.14417, val_recall@20: 0.143, val_precision@20: 0.04231, val_ndcg@20: 0.09538\n",
            "[Iteration 9600/10000] train_loss: -1620.6731, val_loss: -1198.74548, val_recall@20: 0.14468, val_precision@20: 0.04259, val_ndcg@20: 0.09596\n",
            "[Iteration 9800/10000] train_loss: -1629.25439, val_loss: -1202.77014, val_recall@20: 0.14507, val_precision@20: 0.04268, val_ndcg@20: 0.09628\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_recall_at_ks = []\n",
        "\n",
        "for iter in tqdm(range(ITERATIONS)):\n",
        "    # forward propagation  \n",
        "    users_emb_final, users_emb_0,  pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0 \\\n",
        "                = get_embs_for_bpr(model, train_edge_index)\n",
        "    \n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, \n",
        "                          users_emb_0, \n",
        "                          pos_items_emb_final,\n",
        "                          pos_items_emb_0, \n",
        "                          neg_items_emb_final, \n",
        "                          neg_items_emb_0, \n",
        "                          LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # validation set\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            val_loss, recall, precision, ndcg = evaluation(model, \n",
        "                                                           val_edge_index, \n",
        "                                                           [train_edge_index], \n",
        "                                                           K, \n",
        "                                                           LAMBDA\n",
        "                                                          )\n",
        "\n",
        "            print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "\n",
        "            train_losses.append(train_loss.item())\n",
        "            val_losses.append(val_loss)\n",
        "            val_recall_at_ks.append(round(recall, 5))\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "423573ef",
      "metadata": {
        "id": "423573ef"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dabdd722",
      "metadata": {
        "id": "dabdd722"
      },
      "source": [
        "# Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "6e32fd3b",
      "metadata": {
        "id": "6e32fd3b",
        "outputId": "6bb4a7b6-4501-4913-bb45-925f17d58859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "203b99c0",
      "metadata": {
        "id": "203b99c0",
        "outputId": "2442eac9-952b-4f24-cb1a-032ebd95b7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "f2 = plt.figure()\n",
        "plt.plot(iters, val_recall_at_ks, label='recall_at_k')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('recall_at_k')\n",
        "plt.title('recall_at_k curves')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "c9c96a3f",
      "metadata": {
        "id": "c9c96a3f",
        "outputId": "3fa0b347-f2c1-45fc-b2d0-9ca5c86e652e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -1213.99683, test_recall@20: 0.12369, test_precision@20: 0.04176, test_ndcg@20: 0.09413\n"
          ]
        }
      ],
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(model, \n",
        "                                                               test_edge_index, \n",
        "                                                               [train_edge_index, val_edge_index], \n",
        "                                                               K, \n",
        "                                                               LAMBDA\n",
        "                                                              )\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "fb7489fd",
      "metadata": {
        "id": "fb7489fd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c63342d6c5cb4032ae29f4c95b3b3ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_279f2ea35143469fb5b7095846f3127d",
              "IPY_MODEL_5c733606b4c84969a92a1887b4aff063",
              "IPY_MODEL_11073034aa7e4cc5b946f6fea772e9c0"
            ],
            "layout": "IPY_MODEL_8da8ab5809b34c9a98bc19e1227ddb1d"
          }
        },
        "279f2ea35143469fb5b7095846f3127d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f80221129484bd9a572500f0efe34a2",
            "placeholder": "â",
            "style": "IPY_MODEL_42f47230c84e4301a9ebef4db8939560",
            "value": "100%"
          }
        },
        "5c733606b4c84969a92a1887b4aff063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e96eebab901b4360bc64f1232f533be7",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cb666ea2e2b483590c27ff9714e1de5",
            "value": 10000
          }
        },
        "11073034aa7e4cc5b946f6fea772e9c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5417742a2e6746149121185dce42df29",
            "placeholder": "â",
            "style": "IPY_MODEL_35f791d750da43adb152af980f7a121a",
            "value": " 10000/10000 [59:17&lt;00:00,  2.90it/s]"
          }
        },
        "8da8ab5809b34c9a98bc19e1227ddb1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f80221129484bd9a572500f0efe34a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f47230c84e4301a9ebef4db8939560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e96eebab901b4360bc64f1232f533be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb666ea2e2b483590c27ff9714e1de5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5417742a2e6746149121185dce42df29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35f791d750da43adb152af980f7a121a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}